{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Credit Card Requests Approval\n",
    "\n",
    "#### The purpose of this project is to predict wether a credit card request will be approved based on  clients' information. Historical data of previuos requests are used to develop a logistic regression model.\n",
    "\n",
    "#### For the scaling task, I utilize to methods, normalization and standardization, and compare their effect of the model preformance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(689, 16)\n",
      "   b  30.83      0  u  g  w  v  1.25  t t.1  01  f g.1  00202  0.1  +\n",
      "0  a  58.67  4.460  u  g  q  h  3.04  t   t   6  f   g  00043  560  +\n",
      "1  a  24.50  0.500  u  g  q  h  1.50  t   f   0  f   g  00280  824  +\n",
      "2  b  27.83  1.540  u  g  w  v  3.75  t   t   5  t   g  00100    3  +\n",
      "3  b  20.17  5.625  u  g  w  v  1.71  t   f   0  f   s  00120    0  +\n",
      "4  b  32.08  4.000  u  g  m  v  2.50  t   f   0  t   g  00360    0  +\n",
      "  Male    Age   Debt Married BankCustomer EducationLevel Ethnicity  \\\n",
      "0    a  58.67  4.460       u            g              q         h   \n",
      "1    a  24.50  0.500       u            g              q         h   \n",
      "2    b  27.83  1.540       u            g              w         v   \n",
      "3    b  20.17  5.625       u            g              w         v   \n",
      "4    b  32.08  4.000       u            g              m         v   \n",
      "\n",
      "   YearsEmployed PriorDefault Employed  CreditScore DriverLicense Citizen  \\\n",
      "0           3.04            t        t            6             f       g   \n",
      "1           1.50            t        f            0             f       g   \n",
      "2           3.75            t        t            5             t       g   \n",
      "3           1.71            t        f            0             f       s   \n",
      "4           2.50            t        f            0             t       g   \n",
      "\n",
      "  ZipCode  Income Approved  \n",
      "0   00043     560        +  \n",
      "1   00280     824        +  \n",
      "2   00100       3        +  \n",
      "3   00120       0        +  \n",
      "4   00360       0        +  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cc = pd.read_csv('data.csv')\n",
    "\n",
    "print(cc.shape)\n",
    "\n",
    "print(cc.head())\n",
    "\n",
    "# assigning columns name form codebook\n",
    "cc.columns = ['Male','Age','Debt','Married','BankCustomer',\n",
    "              'EducationLevel','Ethnicity','YearsEmployed',\n",
    "              'PriorDefault','Employed','CreditScore',\n",
    "              'DriverLicense','Citizen','ZipCode','Income',\n",
    "              'Approved']\n",
    "\n",
    "print(cc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 689 entries, 0 to 688\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Male            689 non-null    object \n",
      " 1   Age             689 non-null    object \n",
      " 2   Debt            689 non-null    float64\n",
      " 3   Married         689 non-null    object \n",
      " 4   BankCustomer    689 non-null    object \n",
      " 5   EducationLevel  689 non-null    object \n",
      " 6   Ethnicity       689 non-null    object \n",
      " 7   YearsEmployed   689 non-null    float64\n",
      " 8   PriorDefault    689 non-null    object \n",
      " 9   Employed        689 non-null    object \n",
      " 10  CreditScore     689 non-null    int64  \n",
      " 11  DriverLicense   689 non-null    object \n",
      " 12  Citizen         689 non-null    object \n",
      " 13  ZipCode         689 non-null    object \n",
      " 14  Income          689 non-null    int64  \n",
      " 15  Approved        689 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.2+ KB\n",
      "None\n",
      "             Debt  YearsEmployed  CreditScore         Income\n",
      "count  689.000000     689.000000   689.000000     689.000000\n",
      "mean     4.765631       2.224819     2.402032    1018.862119\n",
      "std      4.978470       3.348739     4.866180    5213.743149\n",
      "min      0.000000       0.000000     0.000000       0.000000\n",
      "25%      1.000000       0.165000     0.000000       0.000000\n",
      "50%      2.750000       1.000000     0.000000       5.000000\n",
      "75%      7.250000       2.625000     3.000000     396.000000\n",
      "max     28.000000      28.500000    67.000000  100000.000000\n",
      "       Male  Age Married BankCustomer EducationLevel Ethnicity PriorDefault  \\\n",
      "count   689  689     689          689            689       689          689   \n",
      "unique    3  349       4            4             15        10            2   \n",
      "top       b    ?       u            g              c         v            t   \n",
      "freq    467   12     518          518            137       398          360   \n",
      "\n",
      "       Employed DriverLicense Citizen ZipCode Approved  \n",
      "count       689           689     689     689      689  \n",
      "unique        2             2       3     170        2  \n",
      "top           f             f       g   00000        -  \n",
      "freq        395           373     624     132      383  \n"
     ]
    }
   ],
   "source": [
    "print(cc.info())\n",
    "\n",
    "print(cc.describe())\n",
    "\n",
    "print(cc.describe(include=np.object))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables consist of 4 numeric and 12 object.\n",
    "\n",
    "#### Income variable order is very different among numerics. It shows a need for normalization/standardization.\n",
    "\n",
    "#### There are some undefined '?' valuse among data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing '?' with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "cc = cc.replace('?',np.nan)\n",
    "\n",
    "print(cc.isnull().values.sum()) # there are 67 missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing 'nan' with columns mean, for numerics, and with columns most frequent value for objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cc.fillna(cc.mean(), inplace=True)\n",
    "\n",
    "# replace non-numerics with columns most frequent value (if any)\n",
    "for col in cc:\n",
    "    if cc[col].dtype == 'object':\n",
    "        cc = cc.fillna(cc[col].value_counts().index[0])\n",
    "\n",
    "print(cc.isnull().values.sum()) #there is no missing value now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode object Dtype as numeric\n",
    "\n",
    "#### For the classification task using logistic regression, all data type must be numerics. However, labels are treated as classes and the order is ignored. So, while objects are encoded to numbers, there is no need to apply get_dummies or one_hot_encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 689 entries, 0 to 688\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Male            689 non-null    int64  \n",
      " 1   Age             689 non-null    int64  \n",
      " 2   Debt            689 non-null    float64\n",
      " 3   Married         689 non-null    int64  \n",
      " 4   BankCustomer    689 non-null    int64  \n",
      " 5   EducationLevel  689 non-null    int64  \n",
      " 6   Ethnicity       689 non-null    int64  \n",
      " 7   YearsEmployed   689 non-null    float64\n",
      " 8   PriorDefault    689 non-null    int64  \n",
      " 9   Employed        689 non-null    int64  \n",
      " 10  CreditScore     689 non-null    int64  \n",
      " 11  DriverLicense   689 non-null    int64  \n",
      " 12  Citizen         689 non-null    int64  \n",
      " 13  ZipCode         689 non-null    int64  \n",
      " 14  Income          689 non-null    int64  \n",
      " 15  Approved        689 non-null    int64  \n",
      "dtypes: float64(2), int64(14)\n",
      "memory usage: 86.2 KB\n",
      "None\n",
      "     Male  Age    Debt  Married  BankCustomer  EducationLevel  Ethnicity  \\\n",
      "0       0  327   4.460        2             1              11          4   \n",
      "1       0   89   0.500        2             1              11          4   \n",
      "2       1  125   1.540        2             1              13          8   \n",
      "3       1   43   5.625        2             1              13          8   \n",
      "4       1  167   4.000        2             1              10          8   \n",
      "..    ...  ...     ...      ...           ...             ...        ...   \n",
      "684     1   52  10.085        3             3               5          4   \n",
      "685     0   71   0.750        2             1               2          8   \n",
      "686     0   97  13.500        3             3               6          3   \n",
      "687     1   20   0.205        2             1               0          8   \n",
      "688     1  196   3.375        2             1               2          4   \n",
      "\n",
      "     YearsEmployed  PriorDefault  Employed  CreditScore  DriverLicense  \\\n",
      "0             3.04             1         1            6              0   \n",
      "1             1.50             1         0            0              0   \n",
      "2             3.75             1         1            5              1   \n",
      "3             1.71             1         0            0              0   \n",
      "4             2.50             1         0            0              1   \n",
      "..             ...           ...       ...          ...            ...   \n",
      "684           1.25             0         0            0              0   \n",
      "685           2.00             0         1            2              1   \n",
      "686           2.00             0         1            1              1   \n",
      "687           0.04             0         0            0              0   \n",
      "688           8.29             0         0            0              1   \n",
      "\n",
      "     Citizen  ZipCode  Income  Approved  \n",
      "0          0       11     560         0  \n",
      "1          0       95     824         0  \n",
      "2          0       31       3         0  \n",
      "3          2       37       0         0  \n",
      "4          0      114       0         0  \n",
      "..       ...      ...     ...       ...  \n",
      "684        0       89       0         1  \n",
      "685        0       67     394         1  \n",
      "686        0       67       1         1  \n",
      "687        0       95     750         1  \n",
      "688        0        0       0         1  \n",
      "\n",
      "[689 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in cc.columns:\n",
    "        if cc[col].dtype=='object':\n",
    "            cc[col]=le.fit_transform(cc[col])\n",
    "\n",
    "print(cc.info()) #all Dtype are numeric now\n",
    "print(cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "#### I am going to drop a couple irrelevant features intutively. Although some other features may be irrelevant, I let the model to handle it by assigning close to zero coefficient for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(689, 14)\n"
     ]
    }
   ],
   "source": [
    "cc = cc.drop(['DriverLicense', 'ZipCode'], axis=1)\n",
    "\n",
    "print(cc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into a train set and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = cc.iloc[:,:-1].values #also convert to numpy array\n",
    "\n",
    "Y = cc.iloc[:,-1].values  #also convert to numpy array\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,\n",
    "                                test_size=0.25,\n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling 1: Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "norm = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_norm = norm.transform(X_train)\n",
    "\n",
    "X_test_norm = norm.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train a loistic regression model (normal scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(random_state= 0)\n",
    "\n",
    "logreg.fit(X_train_norm, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance (normal scaling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70 12]\n",
      " [14 77]]\n",
      "0.8497109826589595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "#predict\n",
    "Y_pred = logreg.predict(X_test_norm)\n",
    "\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print(accuracy_score(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling 2: Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_std = sc.transform(X_train)\n",
    "\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train a loistic regression model (standard scaling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(random_state= 0)\n",
    "\n",
    "logreg.fit(X_train_std, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance (standard scaling)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67 15]\n",
      " [10 81]]\n",
      "0.8554913294797688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "#predict\n",
    "Y_pred_std = logreg.predict(X_test_std)\n",
    "\n",
    "print(confusion_matrix(Y_test, Y_pred_std))\n",
    "\n",
    "print(accuracy_score(Y_test, Y_pred_std))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "A logistic model is built and tested through both normalization and standardization. The latter method shows a better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
